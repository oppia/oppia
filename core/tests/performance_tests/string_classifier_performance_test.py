# Copyright 2016 The Oppia Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS-IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""Performance tests for string classifier.

Run this script from the Oppia root directory:

    export PYTHONPATH=$PYTHONPATH:.
    python core/tests/performance_tests/string_classifier_performance_test.py

"""

import os
import time
import yaml

from core.domain.classifier_services import StringClassifier

def benchmark(func):
    """ A decorator to measure how much time spent by func

    Args:
        func: function. The function to be measured.

    Returns:
        function. The decorated function by this decorator.
    """
    def time_taken(obj, num):
        """ Measures the time spent by func.

        Args:
            obj: object. The class instance func belongs to.
            num: int. The number of samples to run with.

        Returns:
            Result of func.
        """
        start = time.time()
        result = func(obj, num)
        end = time.time()
        print '%s spent %f seconds for %d instances' % (func.__name__,
                                                        end - start, num)
        return result
    return time_taken

class StringClassifierBenchmarker(object):
    """ Benchmark for string classifier.

    Usage:
        benchmark = StringClassifierBenchmark()
        benchmark.benchmark_on_train()
        benchmark.benchmark_on_predict()

    Attributes:
        examples: list of two-element lists. An item represents a sample
            by [doc, label].
        predict_docs: list. A list of docs for predicting.
        classifier: dict. The model generated by function train.
    """
    def __init__(self):
        """ Initializes StringClassifierBenchmark by parsing the data
        file containing samples
        """
        yaml_path = os.path.join(os.path.dirname(os.path.realpath(__file__)),
                                 '../data/string_classifier_test.yaml')
        doc_to_label = {}
        with open(yaml_path, 'r') as yaml_file:
            yaml_dict = yaml.load(yaml_file)
            interactions = yaml_dict['states']['Home']['interaction']
            for interaction in interactions['answer_groups'][1:]:
                label = interaction['outcome']['feedback'][0]
                for rule in interaction['rule_specs']:
                    if "inputs" in rule and 'training_data' in rule['inputs']:
                        for doc in rule['inputs']['training_data']:
                            if doc not in doc_to_label:
                                doc_to_label[doc] = []
                            doc_to_label[doc].append(label)
        self.examples = [[doc, doc_to_label[doc]] for doc in doc_to_label]
        self.predict_docs = [doc[0] for doc in self.examples]
        self.classifier = None

    @benchmark
    def train(self, num):
        """ Trains a model with num samples.

        Args:
            num: int. The number of samples to run with.

        Returns:
            dict. The resulting dict representing the model.
        """
        string_classifier = StringClassifier()
        string_classifier.load_examples(self.examples[:num])
        classifier_dict = string_classifier.to_dict()
        return classifier_dict

    def benchmark_on_train(self):
        """ Conduct benchmarking on model training at a pace of adding
        100 samples each time
        """
        for num in xrange(100, len(self.examples), 100):
            self.train(num)

    @benchmark
    def predict(self, num):
        """ Predicts the label for num samples with self.classifier.

        Args:
            num: int. The number of samples to run with.
        """
        if not self.classifier:
            raise Exception('No classifier found')
        string_classifier = StringClassifier()
        string_classifier.from_dict(self.classifier)
        doc_ids = string_classifier.add_docs_for_predicting(
            self.predict_docs[:num])
        for i in xrange(len(doc_ids)):
            string_classifier.predict_label_for_doc(doc_ids[i])

    def benchmark_on_predict(self):
        """ Conduct benchmarking on predicting with self.classifier
        at a pace of adding 100 samples each time
        """
        self.classifier = self.train(len(self.examples))
        for num in xrange(100, len(self.predict_docs), 100):
            self.predict(num)


if __name__ == '__main__':
    benchmark = StringClassifierBenchmarker()
    benchmark.benchmark_on_train()
    benchmark.benchmark_on_predict()
