# coding: utf-8
#
# Copyright 2021 The Oppia Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS-IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""Utilities for running Apache Beam tests."""

from __future__ import absolute_import  # pylint: disable=import-only-modules
from __future__ import unicode_literals  # pylint: disable=import-only-modules

import ast
import datetime
import re

from core.tests import test_utils
from jobs import base_jobs
from jobs import job_options
from jobs.io import stub_io
import python_utils

from apache_beam import runners
from apache_beam.testing import test_pipeline
from apache_beam.testing import util as beam_testing_util
import contextlib2


class PipelinedTestBase(test_utils.TestBase):
    """Base class that runs tests within the context of a TestPipeline."""

    # Helpful constants used by tests to create models.
    NOW = datetime.datetime.utcnow()
    YEAR_AGO = NOW - datetime.timedelta(weeks=52)
    YEAR_LATER = NOW + datetime.timedelta(weeks=52)

    def __init__(self, *args, **kwargs):
        super(PipelinedTestBase, self).__init__(*args, **kwargs)
        self.pipeline = test_pipeline.TestPipeline(
            runner=runners.DirectRunner(),
            options=test_pipeline.PipelineOptions(runtime_type_check=True))
        self._close_stack = None

    def setUp(self):
        super(PipelinedTestBase, self).setUp()
        with contextlib2.ExitStack() as stack:
            stack.enter_context(decorate_beam_errors())
            stack.enter_context(self.pipeline)
            self._close_stack = stack.pop_all().close

    def tearDown(self):
        try:
            self._flush_pipeline()
        finally:
            super(PipelinedTestBase, self).tearDown()

    def assert_pcoll_equal(self, actual, expected):
        """Asserts that the given PCollections are equal.

        NOTE: Only one assert_pcoll_*() method may be called in a test, because
        running assertions on pipelines requires flushing and waiting for it to
        complete. If another assertion would need to be run, then the pipeline
        must be populated with values all over again (equivalent to writing a
        new test case).

        Args:
            actual: PCollection. The PCollection generated by the test.
            expected: PCollection. A PCollection with the expected values.

        Raises:
            RuntimeError. A PCollection assertion has already been called.
        """
        if self._close_stack:
            beam_testing_util.assert_that(
                actual, beam_testing_util.equal_to(expected))
            self._flush_pipeline()
        else:
            raise RuntimeError('assert_pcoll_* may be called at most once')

    def assert_pcoll_empty(self, actual):
        """Asserts that the given PCollection is empty.

        NOTE: Only one assert_pcoll_*() method may be called in a test, because
        running assertions on pipelines requires flushing and waiting for it to
        complete. If another assertion would need to be run, then the pipeline
        must be populated with values all over again (equivalent to writing a
        new test case).

        Args:
            actual: PCollection. The PCollection generated by the test.

        Raises:
            RuntimeError. A PCollection assertion has already been called.
        """
        if self._close_stack:
            beam_testing_util.assert_that(
                actual, beam_testing_util.is_empty())
            self._flush_pipeline()
        else:
            raise RuntimeError('assert_pcoll_* may be called at most once')

    def create_model(self, model_class, **properties):
        """Helper method for creating valid models with common default values.

        Args:
            model_class: *. A subclass of BaseModel.
            **properties: dict(str: *). Properties to assign to the model. By
                default, this method will try to fill the required properties
                with default values.

        Returns:
            *. A new instance of the given model type.

        Raises:
            ValueError. A required property's default value is invalid.
        """
        property_values = {
            p._name: p._default for p in model_class._properties.values() # pylint: disable=protected-access
            if p._required # pylint: disable=protected-access
        }
        property_values['created_on'] = self.YEAR_AGO
        property_values['last_updated'] = self.YEAR_AGO
        property_values.update(properties)
        return model_class(**property_values)

    def _flush_pipeline(self):
        """Flushes the pipeline and waits for it to finish running."""
        if self._close_stack:
            self._close_stack()
            self._close_stack = None


class JobTestBase(PipelinedTestBase):
    """Base class with helpful methods for testing Oppia's jobs.

    Subclasses must add the class constant JOB_CLASS to use the helper methods.
    """

    JOB_CLASS = base_jobs.JobBase # NOTE: run() raises a NotImplementedError.

    def __init__(self, *args, **kwargs):
        super(JobTestBase, self).__init__(*args, **kwargs)
        self.model_io_stub = stub_io.ModelIoStub()
        self.pipeline.options.view_as(job_options.JobOptions).model_getter = (
            self.model_io_stub.get_models)

    def tearDown(self):
        self.model_io_stub.clear()
        super(JobTestBase, self).tearDown()

    def run_job(self):
        """Runs a new instance of self.JOB_CLASS and returns its output.

        Test authors should override this method if their jobs need arguments
        for their run() method, for example:

            class FooJob(JobBase):
                def run(self, model_kind):
                    pass

        Should override this method to provide a value for `model_kind`.

        Returns:
            PCollection. The output of the job.
        """
        return self.JOB_CLASS(self.pipeline).run()

    def assert_job_output_is(self, expected):
        """Asserts the output of self.JOB_CLASS matches the given PCollection.

        Args:
            expected: PCollection. A PCollection with the expected values.
        """
        self.assert_pcoll_equal(self.run_job(), expected)

    def assert_job_output_is_empty(self):
        """Asserts that the output of self.JOB_CLASS is an empty PCollection."""
        self.assert_pcoll_empty(self.run_job())


@contextlib2.contextmanager
def decorate_beam_errors():
    """Context manager to improve the readability of beam_testing_util errors.

    The beam_testing_util module raises exceptions with a single string of
    repr()'d lists as the message. The items end up appearing on one long line,
    making it difficult to read when the elements of the lists are very long
    (which they tend to be especially for Oppia's audit errors).

    This context manager tries to split the list elements into lines, so that
    it's easier to read which errors occurred and why. If it cannot parse the
    message successfully, it will raise the same message.

    Yields:
        None. Nothing.

    Raises:
        AssertionError. The decorated exception.
    """
    try:
        yield
    except beam_testing_util.BeamAssertException as exception:
        exception_message = python_utils.UNICODE(exception)
        match = (
            re.match(
                r'.*'
                r', unexpected elements (?P<unexpected>.*)'
                r', missing elements (?P<missing>.*)'
                r' \[(?P<context>while running .*)\]',
                exception_message)
            or re.match(
                r'.*'
                r', unexpected elements (?P<unexpected>.*)'
                r' \[(?P<context>while running .*)\]',
                exception_message)
            or re.match(
                r'.*'
                r', missing elements (?P<missing>.*)'
                r' \[(?P<context>while running .*)\]',
                exception_message)
            or re.match(
                r'.*'
                r'\[\] == (?P<unexpected>.*)'
                r' \[(?P<context>while running .*)\]',
                exception_message)
        )

        if match:
            groupdict = match.groupdict()
        else:
            raise AssertionError(exception_message)

        unexpected_elements = groupdict.get('unexpected', None)
        try:
            unexpected_elements = (
                ast.literal_eval(unexpected_elements)
                if unexpected_elements else None)
        except (SyntaxError, ValueError):
            raise AssertionError(exception_message)

        missing_elements = groupdict.get('missing', None)
        try:
            missing_elements = (
                ast.literal_eval(missing_elements)
                if missing_elements else None)
        except (SyntaxError, ValueError):
            raise AssertionError(exception_message)

        error_lines = [
            'failed %s' % match.group('context'),
            '',
        ]
        if unexpected_elements:
            error_lines.append('Unexpected:')
            error_lines.extend('    %r' % e for e in unexpected_elements)
        if unexpected_elements and missing_elements:
            error_lines.append('')
        if missing_elements:
            error_lines.append('Missing:')
            error_lines.extend('    %r' % e for e in missing_elements)
        error_lines.append('')
        raise AssertionError('\n'.join(error_lines))
